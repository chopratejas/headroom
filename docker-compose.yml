services:
  headroom-proxy:
    build: .
    command: ["--host", "0.0.0.0"]
    environment:
      - HEADROOM_HOST=0.0.0.0
      # if you want to use a custom OpenAI-compatible API endpoint,
      # uncomment and set the following line with the desired URL
      # - OPENAI_TARGET_API_URL=https://api.x.ai
    ports:
      - "8787:8787"
    depends_on:
      - qdrant
      - neo4j

  # Vector database for semantic search
  qdrant:
    image: qdrant/qdrant:latest
    ports:
      - "6333:6333"  # REST API
      - "6334:6334"  # gRPC
    volumes:
      - qdrant_data:/qdrant/storage
    environment:
      - QDRANT__SERVICE__GRPC_PORT=6334

  # Graph database for relationships and multi-hop reasoning
  neo4j:
    image: neo4j:5.15.0
    ports:
      - "7474:7474"  # HTTP (Browser)
      - "7687:7687"  # Bolt
    volumes:
      - neo4j_data:/data
    environment:
      - NEO4J_AUTH=neo4j/password
      - NEO4J_PLUGINS=["apoc"]
      - NEO4J_apoc_export_file_enabled=true
      - NEO4J_apoc_import_file_enabled=true
      - NEO4J_apoc_import_file_use__neo4j__config=true

volumes:
  qdrant_data:
  neo4j_data:
